{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используемые сторонние библотеки\n",
    "\n",
    "* keras (2.4.3)\n",
    "* matplotlib (3.2.1)\n",
    "* tensorflow (2.2.0)\n",
    "* pandas (1.0.3)\n",
    "* sklearn (0.22.1)\n",
    "* numpy (1.18.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# игнорируем warnings, чтобы не захламлять вывод\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем зависимости\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import tensorflow as tf\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Conv1D, Dropout, Dense\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "plt.style.use('ggplot')\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции, связанные с предобработкой\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Создает массив возможных кусков из временного ряда, \n",
    "    таких что они включают n_in элементов как обучающую часть, \n",
    "    и n_out как предсказываемую. По сути устраняет \"краевые эфекты\"\n",
    "    Метод взят из интернета.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Считает разницу между элементами временного ряда,\n",
    "    отстоящими друг от друга на interval\n",
    "    \"\"\"\n",
    "    \n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "    \n",
    "    \"\"\"\n",
    "    Преобразует данные с помощью нахождения разности (тк данные имеют четкий тренд) и шкалирования,\n",
    "    формирует тренировочную и обучающую части выборки\n",
    "    \"\"\"\n",
    "    \n",
    "    raw_values = series.values\n",
    "    \n",
    "    diff_series = difference(raw_values, 1)\n",
    "    diff_values = diff_series.values\n",
    "    diff_values = diff_values.reshape(len(diff_values), 1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_values = scaler.fit_transform(diff_values)\n",
    "    scaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "    supervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "    supervised_values = supervised.values\n",
    "    \n",
    "    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "    return scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция построения сети\n",
    "\n",
    "def fit_lstm(\n",
    "    train, \n",
    "    n_lag, \n",
    "    n_seq, \n",
    "    nb_epoch, \n",
    "    n_neurons, \n",
    "    learning_rate, \n",
    "    validation_size, \n",
    "    n_batch=1,\n",
    "    verbose=2\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Создает и обучает нейросеть с учетом выбранных параметров.\n",
    "    Возвращает саму модель и историю изменения метрик loss и val_loss в процессе обучения.\n",
    "    \"\"\"\n",
    "    \n",
    "    X, y = train[:, 0:n_lag], train[:, n_lag:]\n",
    "    \n",
    "    \n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    #model.add(Conv1D(32, kernel_size=3))\n",
    "    \n",
    "    model.add(LSTM(\n",
    "        n_neurons, \n",
    "        batch_input_shape=(n_batch, X.shape[1], X.shape[2]), \n",
    "        stateful=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt, metrics=['accuracy', 'mae'])\n",
    "    \n",
    "        \n",
    "    history = model.fit(\n",
    "        X, y, \n",
    "        epochs=n_epochs, \n",
    "        batch_size=n_batch, \n",
    "        validation_split=validation_size, \n",
    "        verbose=verbose, \n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=16, min_delta=1e-4,restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "    return model, history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции, выполняющие прогноз\n",
    "\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "    \n",
    "    \"\"\"\n",
    "    Предсказание предстоящих значений после заданной точки\n",
    "    \"\"\"\n",
    "    \n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    forecast = model.predict(X, batch_size=n_batch)\n",
    "    return [x for x in forecast[0, :]]\n",
    "\n",
    "\n",
    "def make_forecasts(model, test, n_lag, n_seq, n_batch=1):\n",
    "    \"\"\"\n",
    "    Делает предсказания с помощью переданной модели\n",
    "    для всех временных участков из test\n",
    "    \"\"\"\n",
    "    forecasts = list()\n",
    "    for i in range(len(test)):\n",
    "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "        forecast = forecast_lstm(model, X, n_batch)\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "def inverse_difference(last_ob, forecast):\n",
    "    \"\"\"\n",
    "    Перевод значений из разности к абсолютным \n",
    "    \"\"\"\n",
    "    \n",
    "    inverted = list()\n",
    "    inverted.append(forecast[0] + last_ob)\n",
    "    \n",
    "    for i in range(1, len(forecast)):\n",
    "        inverted.append(forecast[i] + inverted[i-1])\n",
    "    return inverted\n",
    "\n",
    "\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "    \n",
    "    \"\"\"\n",
    "    Обратное преобразование данных (после шкалирования и взятия разности)\n",
    "    \"\"\"\n",
    "    \n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        \n",
    "        forecast = array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "        \n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "        \n",
    "        index = len(series) - n_test + i - 1\n",
    "        last_ob = series.values[index]\n",
    "        inv_diff = inverse_difference(last_ob, inv_scale)\n",
    "        \n",
    "        inverted.append(inv_diff)\n",
    "    return inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции для численной и визуальной оценки качества модели\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_forecasts_acc(test, forecasts, n_lag, n_seq):\n",
    "    \"\"\"\n",
    "    Расчет точности по направлению изменения\n",
    "    \"\"\"\n",
    "    actual = [row for row in test]\n",
    "    predicted = [forecast for forecast in forecasts]\n",
    "    \n",
    "    actual_binary = []\n",
    "    predicted_binary = []\n",
    "    \n",
    "    for j in range(1,len(predicted)):\n",
    "        actual_diff = np.sign(np.diff(\n",
    "            [actual[j-1][0]] + actual[j]\n",
    "        ))\n",
    "        pred_diff = np.sign(np.diff(\n",
    "            [predicted[j-1][0]] + predicted[j]\n",
    "        ))\n",
    "        \n",
    "        actual_binary += list(actual_diff)\n",
    "        predicted_binary += list(pred_diff)\n",
    "        \n",
    "    print('Binary acccuracy:', accuracy_score(actual_binary, predicted_binary))\n",
    "\n",
    "\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "    \n",
    "    \"\"\"\n",
    "    Расчет и вывод метрики RMSE для каждой удаленности предсказания\n",
    "    \"\"\"\n",
    "    for i in range(n_seq):\n",
    "        actual = [row[i] for row in test]\n",
    "        predicted = [forecast[i] for forecast in forecasts]\n",
    "                  \n",
    "        \n",
    "        \n",
    "        rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "        print('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "\n",
    "def plot_forecasts(series, c, forecasts, n_test, save=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Отрисовка графика предсказаний из каждой точки тестовой выборки\n",
    "    График полный (Включает весь train sample).\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(14,7))\n",
    "    \n",
    "    plt.plot(series.values)\n",
    "    \n",
    "    for i in range(len(forecasts)):\n",
    "        off_s = len(series) - n_test + i - 1\n",
    "        off_e = off_s + len(forecasts[i]) + 1\n",
    "        xaxis = [x for x in range(off_s, off_e)]\n",
    "        yaxis = [series.values[off_s]] + forecasts[i]\n",
    "        plt.plot(xaxis, yaxis, color='green')\n",
    "        \n",
    "    \n",
    "    plt.title('Forecasts Plot: ' + c)\n",
    "    plt.xlabel('Time point')\n",
    "    plt.ylabel('log value')\n",
    "    if save is not None:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save, dpi=300)\n",
    "        \n",
    "    plt.close()\n",
    "    \n",
    "def plot_forecasts_cropped(series, c, forecasts, n_test, save=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Отрисовка графика предсказаний из каждой точки тестовой выборки\n",
    "    График обрезанный для лучшей читаемости\n",
    "    (Включает небольшую часть train sample).\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(14,7))\n",
    "    \n",
    "    plt.plot(series.values)\n",
    "    \n",
    "    for i in range(len(forecasts)):\n",
    "        off_s = len(series) - n_test + i - 1\n",
    "        off_e = off_s + len(forecasts[i]) + 1\n",
    "        xaxis = [x for x in range(off_s, off_e)]\n",
    "        yaxis = [series.values[off_s]] + forecasts[i]\n",
    "        plt.plot(xaxis, yaxis, color='green')\n",
    "        \n",
    "    plt.xlim([len(series) - 2*n_test, len(series)])\n",
    "    plt.ylim(\n",
    "        [min(series[-2*n_test:]), max(series[-2*n_test:])]\n",
    "    )\n",
    "    \n",
    "    plt.title('Forecasts Plot: ' + c)\n",
    "    plt.xlabel('Time point')\n",
    "    plt.ylabel('log value')\n",
    "    if save is not None:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save, dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT RESULTS\n",
      "Country\tval_loss\tval_accuracy\tval_mae\n",
      "Russian Federation\t0.3106\t0.4286\t0.4399\n",
      "Binary acccuracy: 0.6868686868686869\n",
      "United States\t0.4077\t0.6984\t0.4812\n",
      "Binary acccuracy: 0.569023569023569\n",
      "United Kingdom\t0.3197\t0.3651\t0.4157\n",
      "Binary acccuracy: 0.4882154882154882\n",
      "Germany\t0.5432\t0.6222\t0.5841\n",
      "Binary acccuracy: 0.6902356902356902\n",
      "China, Hong Kong SAR\t0.4966\t0.4603\t0.5391\n",
      "Binary acccuracy: 0.5925925925925926\n",
      "Canada\t0.3112\t0.6825\t0.411\n",
      "Binary acccuracy: 0.6902356902356902\n",
      "Japan\t0.5868\t0.7302\t0.5511\n",
      "Binary acccuracy: 0.7104377104377104\n",
      "Turkey\t0.19\t0.5556\t0.3308\n",
      "Binary acccuracy: 0.5892255892255892\n",
      "Denmark\t0.377\t0.5873\t0.4878\n",
      "Binary acccuracy: 0.6734006734006734\n",
      "Maldives\t0.1179\t0.4286\t0.2897\n",
      "Binary acccuracy: 0.48148148148148145\n",
      "Sweden\t0.4075\t0.6667\t0.5022\n",
      "Binary acccuracy: 0.6296296296296297\n",
      "Korea, Republic of\t0.1987\t0.5079\t0.3252\n",
      "Binary acccuracy: 0.5387205387205387\n",
      "Switzerland\t0.3455\t0.6667\t0.4511\n",
      "Binary acccuracy: 0.7171717171717171\n",
      "Tunisia\t0.365\t0.4138\t0.4575\n",
      "Binary acccuracy: 0.5454545454545454\n",
      "Malaysia\t0.5475\t0.5849\t0.5836\n",
      "Binary acccuracy: 0.5892255892255892\n",
      "Argentina\t0.4014\t0.5556\t0.476\n",
      "Binary acccuracy: 0.7239057239057239\n"
     ]
    }
   ],
   "source": [
    "# В ЭТОЙ ЯЧЕЙКЕ ЦИКЛ ДЛЯ ИМПОРТА! ДЛЯ ЭКСПОРТА В СЛЕДУЮЩЕЙ ЯЧЕЙКЕ!\n",
    "\n",
    "\n",
    "# Все параметры\n",
    "\n",
    "n_lag = 36 # длина фрагмента временного ряда, используемая для предсказания\n",
    "n_seq = 3 # количество временных точек, для которых будет строиться предсказание\n",
    "n_test = 100 # абсолютный размер тестовой выборки\n",
    "validation_size=0.1 # относительный размер валидационной выборки из трейна\n",
    "n_epochs = 1000 # число эпох обучения\n",
    "n_neurons = 64 # число LSTM нейронов\n",
    "learning_rate = 1e-5 # как быстро двигаемся по весам в процессе оптимизации\n",
    "LOG = True # будем ли логарифимировать\n",
    "\n",
    "\n",
    "all_countries = [\n",
    "    'Russian Federation',\n",
    "    'United States',\n",
    "    'United Kingdom',\n",
    "    'Germany',\n",
    "    'China, Hong Kong SAR',\n",
    "    'Canada',\n",
    "    'Japan',\n",
    "    'Turkey',\n",
    "    'Denmark',\n",
    "    'Maldives',\n",
    "    'Sweden',\n",
    "    'Korea, Republic of',\n",
    "    'Switzerland',\n",
    "    'Tunisia',\n",
    "    'Malaysia',\n",
    "    'Argentina',\n",
    "]\n",
    "\n",
    "# читаем табличку, вытаскиваем данные импорта США как удобный вариант для обучения\n",
    "dataframe = pd.read_csv('MBSComtrade.csv')\n",
    "dataframe['period_in_date'] = pd.to_datetime(dataframe['period_in_date'])\n",
    "\n",
    "print('IMPORT RESULTS')\n",
    "print(\n",
    "    'Country',\n",
    "    'val_loss',\n",
    "    'val_accuracy',\n",
    "    'val_mae',\n",
    "    sep='\\t'\n",
    ")\n",
    "\n",
    "\n",
    "for country in all_countries:\n",
    "\n",
    "    test_c = country\n",
    "    country_subset = dataframe[dataframe.country_english_name == test_c]\n",
    "\n",
    "    country_import = country_subset[country_subset.trade_flow_desc == 'Imports']\n",
    "    country_export = country_subset[country_subset.trade_flow_desc == 'Exports']\n",
    "\n",
    "    series = country_import.value\n",
    "\n",
    "\n",
    "    # если надо, логарифмируем\n",
    "    if LOG == True:\n",
    "\n",
    "        for i in series.index:\n",
    "            series[i] = np.log(series[i])\n",
    "\n",
    "\n",
    "    # готовим данные\n",
    "    scaler, train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
    "\n",
    "    # строим модель\n",
    "    model, history = fit_lstm(\n",
    "        train, \n",
    "        n_lag, \n",
    "        n_seq, \n",
    "        n_epochs, \n",
    "        n_neurons, \n",
    "        learning_rate,\n",
    "        validation_size,\n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    print(\n",
    "        country, \n",
    "        round(history['val_loss'][-1], 4), \n",
    "        round(history['val_accuracy'][-1], 4), \n",
    "        round(history['val_mae'][-1], 4), \n",
    "        sep='\\t'\n",
    "    )\n",
    "\n",
    "    #рисуем метрики\n",
    "    fig, axs = plt.subplots(1,2, figsize=(14,7))\n",
    "\n",
    "    axs[0].plot(history['val_loss'])\n",
    "    axs[0].set_title('Validation loss: '+ test_c)\n",
    "    axs[0].set_xlabel('Step')\n",
    "    axs[0].set_ylabel('loss')\n",
    "\n",
    "\n",
    "    axs[1].plot(history['val_mae'])\n",
    "    axs[1].set_title('Validation MAE: ' + test_c)\n",
    "    axs[1].set_xlabel('Step')\n",
    "    axs[1].set_ylabel('MAE')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Models_quality_pics_import/ModelQual_{}.png'.format(test_c), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # строим предсказания\n",
    "    forecasts = make_forecasts(model, test, n_lag, n_seq)\n",
    "    forecasts = inverse_transform(series, forecasts, scaler, n_test+2)\n",
    "\n",
    "\n",
    "    # вытаскиваем реальные сценарии\n",
    "    actual = [row[n_lag:] for row in test]\n",
    "    actual = inverse_transform(series, actual, scaler, n_test+2)\n",
    "\n",
    "    # на них считаем метрики RMSE\n",
    "    evaluate_forecasts_acc(actual, forecasts, n_lag, n_seq)\n",
    "\n",
    "    # рисуем\n",
    "    plot_forecasts(\n",
    "        series, \n",
    "        test_c,\n",
    "        forecasts, \n",
    "        n_test+2, \n",
    "        save='Forecasts_pics_import/Forecasts_{}.png'.format(test_c)\n",
    "    )\n",
    "    \n",
    "    plot_forecasts_cropped(\n",
    "        series, \n",
    "        test_c,\n",
    "        forecasts, \n",
    "        n_test+2, \n",
    "        save='Forecasts_pics_import/Forecasts_crop_{}.png'.format(test_c)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPORT RESULTS\n",
      "Country\tval_loss\tval_accuracy\tval_mae\n",
      "Russian Federation\t0.4719\t0.2857\t0.4975\n",
      "Binary acccuracy: 0.5555555555555556\n",
      "United States\t0.2308\t0.6984\t0.371\n",
      "Binary acccuracy: 0.5959595959595959\n",
      "United Kingdom\t0.3426\t0.3016\t0.4241\n",
      "Binary acccuracy: 0.468013468013468\n",
      "Germany\t0.5252\t0.7111\t0.5816\n",
      "Binary acccuracy: 0.7373737373737373\n",
      "China, Hong Kong SAR\t0.3401\t0.6032\t0.4442\n",
      "Binary acccuracy: 0.6127946127946128\n",
      "Canada\t0.5554\t0.5714\t0.5467\n",
      "Binary acccuracy: 0.5521885521885522\n",
      "Japan\t0.1774\t0.7778\t0.3233\n",
      "Binary acccuracy: 0.8585858585858586\n",
      "Turkey\t0.2865\t0.3333\t0.4425\n",
      "Binary acccuracy: 0.5892255892255892\n",
      "Denmark\t0.7538\t0.5397\t0.7162\n",
      "Binary acccuracy: 0.6195286195286195\n",
      "Maldives\t0.5778\t0.3333\t0.617\n",
      "Binary acccuracy: 0.46464646464646464\n",
      "Sweden\t0.4067\t0.6667\t0.51\n",
      "Binary acccuracy: 0.6127946127946128\n",
      "Korea, Republic of\t0.178\t0.4762\t0.3147\n",
      "Binary acccuracy: 0.5420875420875421\n",
      "Switzerland\t0.2523\t0.6825\t0.38\n",
      "Binary acccuracy: 0.7138047138047138\n",
      "Tunisia\t0.1787\t0.2586\t0.3472\n",
      "Binary acccuracy: 0.5555555555555556\n",
      "Malaysia\t0.7266\t0.6226\t0.6542\n",
      "Binary acccuracy: 0.5892255892255892\n",
      "Argentina\t0.4208\t0.5238\t0.5184\n",
      "Binary acccuracy: 0.632996632996633\n"
     ]
    }
   ],
   "source": [
    "# В ЭТОЙ ЯЧЕЙКЕ ЦИКЛ ДЛЯ ЭКСПОРТА! ДЛЯ ИМПОРТА В ПРЕДЫДУЩЕЙ ЯЧЕЙКЕ!\n",
    "\n",
    "\n",
    "# Все параметры\n",
    "\n",
    "n_lag = 36 # длина фрагмента временного ряда, используемая для предсказания\n",
    "n_seq = 3 # количество временных точек, для которых будет строиться предсказание\n",
    "n_test = 100 # абсолютный размер тестовой выборки\n",
    "validation_size=0.1 # относительный размер валидационной выборки из трейна\n",
    "n_epochs = 1000 # число эпох обучения\n",
    "n_neurons = 64 # число LSTM нейронов\n",
    "learning_rate = 1e-5 # как быстро двигаемся по весам в процессе оптимизации\n",
    "LOG = True # будем ли логарифимировать\n",
    "\n",
    "\n",
    "all_countries = [\n",
    "    'Russian Federation',\n",
    "    'United States',\n",
    "    'United Kingdom',\n",
    "    'Germany',\n",
    "    'China, Hong Kong SAR',\n",
    "    'Canada',\n",
    "    'Japan',\n",
    "    'Turkey',\n",
    "    'Denmark',\n",
    "    'Maldives',\n",
    "    'Sweden',\n",
    "    'Korea, Republic of',\n",
    "    'Switzerland',\n",
    "    'Tunisia',\n",
    "    'Malaysia',\n",
    "    'Argentina',\n",
    "]\n",
    "\n",
    "# читаем табличку, вытаскиваем данные импорта США как удобный вариант для обучения\n",
    "dataframe = pd.read_csv('MBSComtrade.csv')\n",
    "dataframe['period_in_date'] = pd.to_datetime(dataframe['period_in_date'])\n",
    "\n",
    "\n",
    "print('EXPORT RESULTS')\n",
    "print(\n",
    "    'Country',\n",
    "    'val_loss',\n",
    "    'val_accuracy',\n",
    "    'val_mae',\n",
    "    sep='\\t'\n",
    ")\n",
    "\n",
    "for country in all_countries:\n",
    "\n",
    "    test_c = country\n",
    "    country_subset = dataframe[dataframe.country_english_name == test_c]\n",
    "\n",
    "    country_import = country_subset[country_subset.trade_flow_desc == 'Imports']\n",
    "    country_export = country_subset[country_subset.trade_flow_desc == 'Exports']\n",
    "\n",
    "    series = country_export.value\n",
    "\n",
    "\n",
    "    # если надо, логарифмируем\n",
    "    if LOG == True:\n",
    "\n",
    "        for i in series.index:\n",
    "            series[i] = np.log(series[i])\n",
    "\n",
    "\n",
    "    # готовим данные\n",
    "    scaler, train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
    "\n",
    "    # строим модель\n",
    "    model, history = fit_lstm(\n",
    "        train, \n",
    "        n_lag, \n",
    "        n_seq, \n",
    "        n_epochs, \n",
    "        n_neurons, \n",
    "        learning_rate,\n",
    "        validation_size,\n",
    "        verbose=0,\n",
    "    )\n",
    "    \n",
    "    print(\n",
    "        country, \n",
    "        round(history['val_loss'][-1], 4), \n",
    "        round(history['val_accuracy'][-1], 4), \n",
    "        round(history['val_mae'][-1], 4), \n",
    "        sep='\\t'\n",
    "    )\n",
    "\n",
    "    #рисуем метрики\n",
    "    fig, axs = plt.subplots(1,2, figsize=(14,7))\n",
    "\n",
    "    axs[0].plot(history['val_loss'])\n",
    "    axs[0].set_title('Validation loss: '+ test_c)\n",
    "    axs[0].set_xlabel('Step')\n",
    "    axs[0].set_ylabel('loss')\n",
    "\n",
    "\n",
    "    axs[1].plot(history['val_mae'])\n",
    "    axs[1].set_title('Validation MAE: ' + test_c)\n",
    "    axs[1].set_xlabel('Step')\n",
    "    axs[1].set_ylabel('MAE')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Models_quality_pics_export//ModelQual_{}.png'.format(test_c), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    # строим предсказания\n",
    "    forecasts = make_forecasts(model, test, n_lag, n_seq)\n",
    "    forecasts = inverse_transform(series, forecasts, scaler, n_test+2)\n",
    "\n",
    "\n",
    "    # вытаскиваем реальные сценарии\n",
    "    actual = [row[n_lag:] for row in test]\n",
    "    actual = inverse_transform(series, actual, scaler, n_test+2)\n",
    "\n",
    "    # на них считаем метрики RMSE\n",
    "    evaluate_forecasts_acc(actual, forecasts, n_lag, n_seq)\n",
    "\n",
    "    # рисуем\n",
    "    plot_forecasts(\n",
    "        series, \n",
    "        test_c,\n",
    "        forecasts, \n",
    "        n_test+2, \n",
    "        save='Forecasts_pics_export/Forecasts_{}.png'.format(test_c)\n",
    "    )\n",
    "    \n",
    "    plot_forecasts_cropped(\n",
    "        series, \n",
    "        test_c,\n",
    "        forecasts, \n",
    "        n_test+2, \n",
    "        save='Forecasts_pics_export/Forecasts_crop_{}.png'.format(test_c)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
